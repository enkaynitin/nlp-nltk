from nltk.tokenize import sent_tokenize,  word_tokenize


# tokenizing
	#word
	#sentence

# corpora : body of text. ex: journal, speech, English language

# Lexicon - words and their meaning

example_text = "Hello Mr. Smith, how are you doing today? The weather is great and python is awesome. The sky is pinkish-blue. You should not eat cardboard."

print(sent_tokenize(example_text))


